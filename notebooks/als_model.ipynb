{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7545919a-50ef-4db4-a3b7-5f30d5ddc194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382fea2-30ba-43c5-90fb-7ef88307face",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ead476f0-f4ec-487c-85fa-e9f22932c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1ba17c6-1a03-4dd4-b48e-4d13f4b9d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder \\\n",
    "    #.appName(\"Read MovieLens from HDFS\") \\\n",
    "    #.getOrCreate()\n",
    "\n",
    "#spark = SparkSession.builder \\\n",
    "    #.appName(\"ALS Model\") \\\n",
    "    #.config(\"spark.driver.memory\", \"4g\") \\\n",
    "    #.config(\"spark.executor.memory\", \"4g\") \\\n",
    "   # .getOrCreate()\n",
    "\n",
    "#.config(\"spark.hadoop.fs.defaultFS\", \"hdfs://bigdata-node:8088\") \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieLensAnalysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"20\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f8a23-93d5-49de-bf86-fc96e6e8fd21",
   "metadata": {},
   "source": [
    "Lire les fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "557a0df6-d313-4513-81e5-df0c38577e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.option(\"header\", True).csv(\"hdfs:///data/rating.csv\")\n",
    "movies_df = spark.read.option(\"header\", True).csv(\"hdfs:///data/movie.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff832df7-ed4c-4023-b032-1d2d64ec2539",
   "metadata": {},
   "source": [
    "Supprimer les doublons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7488ee5a-a35b-49d8-86ce-2405d9def3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.dropDuplicates()\n",
    "movies_df = movies_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813f66d-4172-4d95-a1f3-7cb0e6575a87",
   "metadata": {},
   "source": [
    "Supprimer les valeurs nulles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac110a7f-bc03-48cd-ac03-ba4ca3251aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.dropna(subset=[\"userId\", \"movieId\", \"rating\"])\n",
    "movies_df = movies_df.dropna(subset=[\"movieId\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ef10c59-cf22-41cd-88f3-9e6776d1de11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:36 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:39 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:40 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:41 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:42 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:43 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:44 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:45 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:46 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:47 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:48 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/05/05 13:53:49 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 31:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|    593|   3.5|2005-04-02 23:31:01|\n",
      "|     1|   1246|   3.5|2004-09-10 03:09:19|\n",
      "|     1|   1350|   3.5|2004-09-10 03:15:58|\n",
      "|     1|   1525|     3|2005-04-02 23:55:50|\n",
      "|     1|   2959|     4|2004-09-10 03:08:18|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2c6cd-83d6-4d67-adde-f46567728dfb",
   "metadata": {},
   "source": [
    "Affichage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f0b20ab-76ea-45b2-a4d3-a87927ff9487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      6|         Heat (1995)|Action|Crime|Thri...|\n",
      "|     12|Dracula: Dead and...|       Comedy|Horror|\n",
      "|     24|       Powder (1995)|        Drama|Sci-Fi|\n",
      "|     31|Dangerous Minds (...|               Drama|\n",
      "|     60|Indian in the Cup...|Adventure|Childre...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06278d09-4288-42f7-80d1-da3ef32d9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = ratings_df.join(\n",
    "    movies_df.select(\"movieId\", \"title\"),\n",
    "    on=\"movieId\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63753215-bcbc-41f4-a201-845eabf65bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+--------------------+\n",
      "|movieId|userId|rating|          timestamp|               title|\n",
      "+-------+------+------+-------------------+--------------------+\n",
      "|      2|     1|   3.5|2005-04-02 23:53:47|      Jumanji (1995)|\n",
      "|     29|     1|   3.5|2005-04-02 23:31:16|City of Lost Chil...|\n",
      "|     32|     1|   3.5|2005-04-02 23:33:39|Twelve Monkeys (a...|\n",
      "|     47|     1|   3.5|2005-04-02 23:32:07|Seven (a.k.a. Se7...|\n",
      "|     50|     1|   3.5|2005-04-02 23:29:40|Usual Suspects, T...|\n",
      "+-------+------+------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "002f42d9-7288-46a9-a49a-67a28b5d3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.withColumnsRenamed({\n",
    "    'userId': 'user',\n",
    "    'movieId': 'movie',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa80e461-4542-48d9-b803-beec718aabb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+-------------------+--------------------+\n",
      "|movie|user|rating|          timestamp|               title|\n",
      "+-----+----+------+-------------------+--------------------+\n",
      "|    2|   1|   3.5|2005-04-02 23:53:47|      Jumanji (1995)|\n",
      "|   29|   1|   3.5|2005-04-02 23:31:16|City of Lost Chil...|\n",
      "|   32|   1|   3.5|2005-04-02 23:33:39|Twelve Monkeys (a...|\n",
      "|   47|   1|   3.5|2005-04-02 23:32:07|Seven (a.k.a. Se7...|\n",
      "|   50|   1|   3.5|2005-04-02 23:29:40|Usual Suspects, T...|\n",
      "+-----+----+------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99d5f476-a971-48b2-9abc-614c68392e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_data = df_data \\\n",
    "    .withColumn(\"user\", col(\"user\").cast(\"int\")) \\\n",
    "    .withColumn(\"movie\", col(\"movie\").cast(\"int\")) \\\n",
    "    .withColumn(\"rating\", col(\"rating\").cast(\"float\")) \\\n",
    "    .withColumn(\"timestamp\", col(\"timestamp\").cast(\"int\")) \\\n",
    "    .withColumn(\"title\", col(\"title\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a7466fe-735f-4b66-89ec-5aeba43e6287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train, df_data_test = df_data.randomSplit([0.8, 0.2], 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "167be899-c3e6-48dc-bad4-add72e4eda5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# import ALS model from spark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# initialise the model \n",
    "als = ALS(maxIter=10, regParam=0.1, rank=10, userCol=\"user\", itemCol=\"movie\", \n",
    "          ratingCol=\"rating\", coldStartStrategy=\"drop\", nonnegative=True)\n",
    "\n",
    "# train model \n",
    "als_model = als.fit(df_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "376f6658-da74-496e-ba0c-4daf4c7c5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_preds = als_model.transform(df_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d35d13e-9426-44fb-b4a8-bfc5edbc1205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 255:=====================================>                  (8 + 4) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+---------+--------------------+----------+\n",
      "|movie|user|rating|timestamp|               title|prediction|\n",
      "+-----+----+------+---------+--------------------+----------+\n",
      "|   47|  95|   3.0|     NULL|Seven (a.k.a. Se7...| 3.0762284|\n",
      "|  262|  95|   3.0|     NULL|Little Princess, ...| 3.4373078|\n",
      "|  446|  95|   3.0|     NULL|Farewell My Concu...| 3.6016524|\n",
      "|  592|  95|   3.0|     NULL|       Batman (1989)|  2.502191|\n",
      "|  708|  95|   4.0|     NULL|Truth About Cats ...|  3.108661|\n",
      "+-----+----+------+---------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "dfs_preds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c131d101-ca69-42f3-93f3-0c0f8d3f54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#als_model.save(\"hdfs:///data/als_prediction_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8454468-2ce4-4ecb-bf96-9fd20df144a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "als_model_loaded = ALSModel.load(\"hdfs:///data/als_prediction_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5004f194-c3c8-41aa-9ee5-dd7fd1b0fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_preds_loaded = als_model_loaded.transform(df_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80881729-ae39-4c05-8360-ff6a0a0510bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_preds_loaded.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c10a083-5f7b-44a8-a2c9-7f6621ebb40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+---------+----------------+\n",
      "|movie|user|rating|timestamp|           title|\n",
      "+-----+----+------+---------+----------------+\n",
      "|    1|   8|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1|  13|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1|  16|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1|  31|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1|  58|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1|  80|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1|  96|   3.5|     NULL|Toy Story (1995)|\n",
      "|    1| 114|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1| 134|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1| 135|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1| 136|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 140|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1| 144|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1| 155|   2.5|     NULL|Toy Story (1995)|\n",
      "|    1| 172|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 204|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 232|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1| 296|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 318|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 330|   4.0|     NULL|Toy Story (1995)|\n",
      "+-----+----+------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_data_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be25fa01-15f4-47fe-a548-18fc446afc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:=======================>                                 (5 + 7) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score = 0.8157736828362929\n",
      "R2 score = 0.39869052585871656\n",
      "MAE score = 0.6375367684273177\n",
      "Explained variance score = 0.4086564056899666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# initiate evaluator\n",
    "eval = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "# calculate rmse\n",
    "rmse = eval.evaluate(dfs_preds_loaded)\n",
    "\n",
    "# reset metric and evaluate mse, R2, mae & explained variance\n",
    "r2 = eval.evaluate(dfs_preds_loaded, {eval.metricName: 'r2'})\n",
    "mae = eval.evaluate(dfs_preds_loaded, {eval.metricName: 'mae'})\n",
    "var = eval.evaluate(dfs_preds_loaded, {eval.metricName: 'var'})\n",
    "\n",
    "\n",
    "print(\n",
    "    \"RMSE score = {}\".format(rmse),\n",
    "    \"R2 score = {}\".format(r2),\n",
    "    \"MAE score = {}\".format(mae),\n",
    "    \"Explained variance score = {}\".format(var),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc72c17a-5ce4-418d-9f3a-5cf57e19380d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===================================================>    (11 + 1) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------------------------------------------------------------------------------------------------------+----------+\n",
      "|user|movie |title                                                                                                 |prediction|\n",
      "+----+------+------------------------------------------------------------------------------------------------------+----------+\n",
      "|29  |128091|Craig Ferguson: A Wee Bit o' Revolution (2009)                                                        |6.5495496 |\n",
      "|29  |121029|No Distance Left to Run (2010)                                                                        |5.922186  |\n",
      "|29  |77736 |Crazy Stone (Fengkuang de shitou) (2006)                                                              |5.7918434 |\n",
      "|29  |129536|Code Name Coq Rouge (1989)                                                                            |5.3435593 |\n",
      "|29  |99243 |Parasites, Les (1999)                                                                                 |5.1454844 |\n",
      "|29  |102119|Yesterday Was a Lie (2008)                                                                            |5.1318784 |\n",
      "|29  |98275 |Octopus, The (Le poulpe) (1998)                                                                       |5.098303  |\n",
      "|29  |120134|Doggiewoggiez! Poochiewoochiez! (2012)                                                                |4.9880137 |\n",
      "|29  |104103|Miss You Can Do It (2013)                                                                             |4.980217  |\n",
      "|29  |107623|2013 Rock and Roll Hall of Fame Induction Ceremony, The (2013)                                        |4.980217  |\n",
      "|29  |79348 |Pearl Jam: Immagine in Cornice - Live in Italy 2006 (2007)                                            |4.9776764 |\n",
      "|29  |100196|Tom Petty and the Heartbreakers: Runnin' Down a Dream (2007)                                          |4.9523377 |\n",
      "|29  |130347|Bill Hicks: Sane Man (1989)                                                                           |4.939438  |\n",
      "|29  |96631 |Deathstalker II (1987)                                                                                |4.928587  |\n",
      "|29  |98328 |Chronicle of My Mother (Waga haha no ki) (2011)                                                       |4.923467  |\n",
      "|29  |109887|Great Passage, The (Fune wo amu) (2013)                                                               |4.923467  |\n",
      "|29  |113555|It Runs in the Family (My Summer Story) (1994)                                                        |4.9078717 |\n",
      "|29  |102107|American Winter (2013)                                                                                |4.8937654 |\n",
      "|29  |72235 |Between the Devil and the Deep Blue Sea (1995)                                                        |4.8588862 |\n",
      "|29  |113043|Loser Takes All! (Qui perd gagne !) (2003)                                                            |4.856163  |\n",
      "|29  |95776 |Bob Funk (2009)                                                                                       |4.8555307 |\n",
      "|29  |89056 |Company: Original Cast Album (1970)                                                                   |4.82715   |\n",
      "|29  |7568  |Love Life (2001)                                                                                      |4.8259597 |\n",
      "|29  |101319|Operation Daybreak (1975)                                                                             |4.8234453 |\n",
      "|29  |107306|Gurren Lagann: The Lights in the Sky are Stars (Gekijô ban Tengen toppa guren ragan: Ragan hen) (2009)|4.8223424 |\n",
      "|29  |126723|Kenny Begins (2009)                                                                                   |4.7995872 |\n",
      "|29  |129514|George Carlin: It's Bad for Ya! (2008)                                                                |4.795023  |\n",
      "|29  |107743|Class of 92, The (2013)                                                                               |4.793573  |\n",
      "|29  |128187|Freedom Song (2000)                                                                                   |4.780411  |\n",
      "|29  |56869 |Drained (O cheiro do Ralo) (2006)                                                                     |4.77037   |\n",
      "|29  |101855|Shepard & Dark (2012)                                                                                 |4.768065  |\n",
      "|29  |75981 |Who Are you Polly Maggoo (Qui êtes-vous, Polly Maggoo?) (1966)                                        |4.7676563 |\n",
      "|29  |128508|Valley Of Flowers (2006)                                                                              |4.764338  |\n",
      "|29  |129241|Tis kakomoiras (1963)                                                                                 |4.762114  |\n",
      "|29  |117525|Ain't in It for My Health: A Film About Levon Helm (2013)                                             |4.756005  |\n",
      "|29  |109529|Everybody Street (2013)                                                                               |4.7555337 |\n",
      "|29  |129451|Ingenious (2009)                                                                                      |4.7422132 |\n",
      "|29  |126397|The Encounter (2010)                                                                                  |4.7365336 |\n",
      "|29  |25749 |Marriage Circle, The (1924)                                                                           |4.7304125 |\n",
      "|29  |116141|The Russian Novel (2013)                                                                              |4.722356  |\n",
      "|29  |113315|Zero Motivation (Efes beyahasei enosh) (2014)                                                         |4.7169676 |\n",
      "|29  |79346 |Smashing Pumpkins: If All Goes Wrong (2008)                                                           |4.7167654 |\n",
      "|29  |103593|Taming the Fire (Ukroshcheniye ognya) (1972)                                                          |4.6998196 |\n",
      "|29  |89819 |Punk in London (1977)                                                                                 |4.694857  |\n",
      "|29  |116951|Bo Burnham: what. (2013)                                                                              |4.69233   |\n",
      "|29  |80417 |Io Island (Iodo) (1977)                                                                               |4.6912127 |\n",
      "|29  |84234 |Simple Simon (I rymden finns inga känslor) (2010)                                                     |4.684553  |\n",
      "|29  |106158|La discrète (1990)                                                                                    |4.6838107 |\n",
      "|29  |101717|Elusive Summer of '68, The (Varljivo leto '68) (1984)                                                 |4.6778274 |\n",
      "|29  |26978 |Kiss or Kill (1997)                                                                                   |4.644303  |\n",
      "|29  |105778|One Small Hitch (2013)                                                                                |4.6369443 |\n",
      "|29  |107382|Whoopi Goldberg Presents Moms Mabley (2013)                                                           |4.630653  |\n",
      "|29  |125922|Gregory Go Boom (2013)                                                                                |4.6220107 |\n",
      "|29  |67135 |Night Has a Thousand Eyes (1948)                                                                      |4.6141257 |\n",
      "|29  |120313|Otakus in Love (2004)                                                                                 |4.61222   |\n",
      "|29  |107643|Here Without Me (Inja bedoone man) (2011)                                                             |4.6120944 |\n",
      "|29  |107713|Meat the Truth (2008)                                                                                 |4.604613  |\n",
      "|29  |99724 |K-11 (2012)                                                                                           |4.6011405 |\n",
      "|29  |84502 |World According to Sesame Street, The (2006)                                                          |4.5953064 |\n",
      "|29  |79866 |Schmatta: Rags to Riches to Rags (2009)                                                               |4.5911474 |\n",
      "|29  |130954|Guter Junge (2008)                                                                                    |4.5858426 |\n",
      "|29  |131027|But Forever in My Mind (1999)                                                                         |4.5858426 |\n",
      "|29  |107730|By the People: The Election of Barack Obama (2009)                                                    |4.584399  |\n",
      "|29  |102912|Hiroshima (2005)                                                                                      |4.5815983 |\n",
      "|29  |93291 |Stone Left Unturned, A (Kovat miehet) (2000)                                                          |4.5803595 |\n",
      "|29  |86061 |Question of Silence, A (De stilte rond Christine M.) (1982)                                           |4.5794244 |\n",
      "|29  |105825|Mustasukkaisuus (1953)                                                                                |4.575901  |\n",
      "|29  |89985 |Trap: What Happened to Our Dream of Freedom, The (2007)                                               |4.568497  |\n",
      "|29  |110097|From Dad to Son (2012)                                                                                |4.5682645 |\n",
      "|29  |128987|Lascars (2009)                                                                                        |4.5682645 |\n",
      "|29  |26459 |Scarlet Pimpernel, The (1982)                                                                         |4.565831  |\n",
      "|29  |54326 |Sierra, La (2005)                                                                                     |4.560083  |\n",
      "|29  |130644|The Garden of Sinners - Chapter 5: Paradox Paradigm (2008)                                            |4.5593905 |\n",
      "|29  |33426 |9 Souls (Nain souruzu) (2003)                                                                         |4.5508785 |\n",
      "|29  |26232 |Rejs (1970)                                                                                           |4.5507    |\n",
      "|29  |81117 |Moth, The (Cma) (1980)                                                                                |4.547665  |\n",
      "|29  |62054 |Friend Among Strangers, Stranger Among Friends (Svoy sredi chuzhikh, chuzhoy sredi svoikh) (1974)     |4.543563  |\n",
      "|29  |79775 |Story of My Life, The (Mensonges et trahisons et plus si affinités...) (2004)                         |4.5421753 |\n",
      "|29  |116183|It's Love I'm After (1937)                                                                            |4.5415983 |\n",
      "|29  |99493 |Girl Walk: All Day (2011)                                                                             |4.5404663 |\n",
      "|29  |25994 |Salt of the Earth (1954)                                                                              |4.54036   |\n",
      "|29  |69493 |Tu£sday (2008)                                                                                        |4.539156  |\n",
      "|29  |84276 |Stewart Lee: If You Prefer a Milder Comedian, Please Ask for One (2010)                               |4.5329733 |\n",
      "|29  |88466 |Broken Sky (El cielo dividido) (2006)                                                                 |4.532732  |\n",
      "|29  |69464 |Angels of the Universe (Englar alheimsins) (2000)                                                     |4.532116  |\n",
      "|29  |115699|Turning Tide (En solitaire) (2013)                                                                    |4.5272827 |\n",
      "|29  |113244|When I Walk (2013)                                                                                    |4.5225058 |\n",
      "|29  |122290|Homeboy (1988)                                                                                        |4.5213532 |\n",
      "|29  |47460 |Peking Opera Blues (Do ma daan) (1986)                                                                |4.5202484 |\n",
      "|29  |68544 |Stolen Collection, (Skradziona kolekcja) (1979)                                                       |4.5129848 |\n",
      "|29  |130034|Stand by Me Doraemon (2014)                                                                           |4.5074973 |\n",
      "|29  |92496 |Dylan Moran: Like, Totally (2006)                                                                     |4.5072584 |\n",
      "|29  |80195 |Shouting Fire: Stories from the Edge of Free Speech (2009)                                            |4.5000587 |\n",
      "|29  |109925|It Is Written in the Stars, Inspector Palmu (Tähdet kertovat, komisario Palmu) (1962)                 |4.4978523 |\n",
      "|29  |103863|Holidays by the Sea (Ni à vendre ni à louer) (2011)                                                   |4.4908934 |\n",
      "|29  |56548 |All Passion Spent (1986)                                                                              |4.4889894 |\n",
      "|29  |102495|Spine Tingler!  The William Castle Story (2007)                                                       |4.484663  |\n",
      "|29  |26674 |Prime Suspect (1991)                                                                                  |4.479828  |\n",
      "|29  |100060|Sunny (Sseo-ni) (2011)                                                                                |4.477886  |\n",
      "|29  |112990|Pursuit of Unhappiness, The (Anleitung zum Unglücklichsein) (2012)                                    |4.47303   |\n",
      "+----+------+------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# ID de l'utilisateur\n",
    "user_id = 29\n",
    "\n",
    "# Créer un DataFrame avec l'utilisateur\n",
    "user_df = spark.createDataFrame([(user_id,)], [\"user\"])\n",
    "\n",
    "# Créer un DataFrame avec tous les films\n",
    "all_movies_df = movies_df.select(col(\"movieId\").cast(\"int\").alias(\"movie\"))\n",
    "\n",
    "# Faire un produit cartésien pour obtenir (user, movie)\n",
    "user_movies_df = user_df.crossJoin(all_movies_df)\n",
    "\n",
    "# Prédire les notes\n",
    "predicted_ratings_df = als_model_loaded.transform(user_movies_df)\n",
    "\n",
    "# ✅ Préparer les titres des films sans ambiguïté\n",
    "movies_renamed_df = movies_df.select(\n",
    "    col(\"movieId\").cast(\"int\").alias(\"movie_id_for_join\"),\n",
    "    \"title\"\n",
    ")\n",
    "\n",
    "# ✅ Join propre entre prédictions et titres\n",
    "result_df = predicted_ratings_df.join(\n",
    "    movies_renamed_df,\n",
    "    predicted_ratings_df.movie == movies_renamed_df.movie_id_for_join,\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Afficher les 10 meilleures prédictions\n",
    "result_df.select(\"user\", \"movie\", \"title\", \"prediction\") \\\n",
    "         .orderBy(col(\"prediction\").desc()) \\\n",
    "         .show(100, truncate=False)\n",
    "\n",
    "#result_df.select(\"user\", \"movie\", \"title\", \"prediction\") \\\n",
    "#         .orderBy(col(\"prediction\").desc()) \\\n",
    "#         .show(truncate=False, n=result_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00dabdc0-90c7-4f34-87dd-8b840afd476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading pymongo-4.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pymongo]m1/2\u001b[0m [pymongo]\n",
      "\u001b[1A\u001b[2KSuccessfully installed dnspython-2.7.0 pymongo-4.12.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9963d448-36f2-4f2e-97b0-bb115a34c3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données insérées dans MongoDB depuis result_df !\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "pdf = result_df.select(\"user\", \"movie\", \"title\", \"prediction\") \\\n",
    "               .orderBy(col(\"prediction\").desc()) \\\n",
    "               .limit(100) \\\n",
    "               .toPandas()\n",
    "\n",
    "client = MongoClient(\"mongodb://mongodb:27017/\")\n",
    "collection = client[\"reco_db\"][\"predictions\"]\n",
    "\n",
    "collection.insert_many(pdf.to_dict(orient=\"records\"))\n",
    "\n",
    "print(\"✅ Données insérées dans MongoDB depuis result_df !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3526bf9-70a7-4ce5-ae16-8f7c220fab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae51c'), 'user': 29, 'movie': 128091, 'title': \"Craig Ferguson: A Wee Bit o' Revolution (2009)\", 'prediction': 6.549549579620361}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae51d'), 'user': 29, 'movie': 121029, 'title': 'No Distance Left to Run (2010)', 'prediction': 5.922185897827148}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae51e'), 'user': 29, 'movie': 77736, 'title': 'Crazy Stone (Fengkuang de shitou) (2006)', 'prediction': 5.791843414306641}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae51f'), 'user': 29, 'movie': 129536, 'title': 'Code Name Coq Rouge (1989)', 'prediction': 5.343559265136719}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae520'), 'user': 29, 'movie': 99243, 'title': 'Parasites, Les (1999)', 'prediction': 5.145484447479248}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae521'), 'user': 29, 'movie': 102119, 'title': 'Yesterday Was a Lie (2008)', 'prediction': 5.13187837600708}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae522'), 'user': 29, 'movie': 98275, 'title': 'Octopus, The (Le poulpe) (1998)', 'prediction': 5.098302841186523}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae523'), 'user': 29, 'movie': 120134, 'title': 'Doggiewoggiez! Poochiewoochiez! (2012)', 'prediction': 4.988013744354248}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae524'), 'user': 29, 'movie': 104103, 'title': 'Miss You Can Do It (2013)', 'prediction': 4.980216979980469}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae525'), 'user': 29, 'movie': 107623, 'title': '2013 Rock and Roll Hall of Fame Induction Ceremony, The (2013)', 'prediction': 4.980216979980469}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae526'), 'user': 29, 'movie': 79348, 'title': 'Pearl Jam: Immagine in Cornice - Live in Italy 2006 (2007)', 'prediction': 4.9776763916015625}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae527'), 'user': 29, 'movie': 100196, 'title': \"Tom Petty and the Heartbreakers: Runnin' Down a Dream (2007)\", 'prediction': 4.952337741851807}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae528'), 'user': 29, 'movie': 130347, 'title': 'Bill Hicks: Sane Man (1989)', 'prediction': 4.9394378662109375}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae529'), 'user': 29, 'movie': 96631, 'title': 'Deathstalker II (1987)', 'prediction': 4.928586959838867}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae52a'), 'user': 29, 'movie': 98328, 'title': 'Chronicle of My Mother (Waga haha no ki) (2011)', 'prediction': 4.92346715927124}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae52b'), 'user': 29, 'movie': 109887, 'title': 'Great Passage, The (Fune wo amu) (2013)', 'prediction': 4.92346715927124}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae52c'), 'user': 29, 'movie': 113555, 'title': 'It Runs in the Family (My Summer Story) (1994)', 'prediction': 4.907871723175049}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae52d'), 'user': 29, 'movie': 102107, 'title': 'American Winter (2013)', 'prediction': 4.893765449523926}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae52e'), 'user': 29, 'movie': 72235, 'title': 'Between the Devil and the Deep Blue Sea (1995)', 'prediction': 4.858886241912842}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae52f'), 'user': 29, 'movie': 113043, 'title': 'Loser Takes All! (Qui perd gagne !) (2003)', 'prediction': 4.856163024902344}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae530'), 'user': 29, 'movie': 95776, 'title': 'Bob Funk (2009)', 'prediction': 4.855530738830566}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae531'), 'user': 29, 'movie': 89056, 'title': 'Company: Original Cast Album (1970)', 'prediction': 4.827149868011475}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae532'), 'user': 29, 'movie': 7568, 'title': 'Love Life (2001)', 'prediction': 4.8259596824646}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae533'), 'user': 29, 'movie': 101319, 'title': 'Operation Daybreak (1975)', 'prediction': 4.8234453201293945}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae534'), 'user': 29, 'movie': 107306, 'title': 'Gurren Lagann: The Lights in the Sky are Stars (Gekijô ban Tengen toppa guren ragan: Ragan hen) (2009)', 'prediction': 4.822342395782471}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae535'), 'user': 29, 'movie': 126723, 'title': 'Kenny Begins (2009)', 'prediction': 4.799587249755859}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae536'), 'user': 29, 'movie': 129514, 'title': \"George Carlin: It's Bad for Ya! (2008)\", 'prediction': 4.795022964477539}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae537'), 'user': 29, 'movie': 107743, 'title': 'Class of 92, The (2013)', 'prediction': 4.793572902679443}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae538'), 'user': 29, 'movie': 128187, 'title': 'Freedom Song (2000)', 'prediction': 4.7804107666015625}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae539'), 'user': 29, 'movie': 56869, 'title': 'Drained (O cheiro do Ralo) (2006)', 'prediction': 4.770370006561279}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae53a'), 'user': 29, 'movie': 101855, 'title': 'Shepard & Dark (2012)', 'prediction': 4.768064975738525}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae53b'), 'user': 29, 'movie': 75981, 'title': 'Who Are you Polly Maggoo (Qui êtes-vous, Polly Maggoo?) (1966)', 'prediction': 4.767656326293945}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae53c'), 'user': 29, 'movie': 128508, 'title': 'Valley Of Flowers (2006)', 'prediction': 4.76433801651001}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae53d'), 'user': 29, 'movie': 129241, 'title': 'Tis kakomoiras (1963)', 'prediction': 4.76211404800415}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae53e'), 'user': 29, 'movie': 117525, 'title': \"Ain't in It for My Health: A Film About Levon Helm (2013)\", 'prediction': 4.756004810333252}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae53f'), 'user': 29, 'movie': 109529, 'title': 'Everybody Street (2013)', 'prediction': 4.755533695220947}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae540'), 'user': 29, 'movie': 129451, 'title': 'Ingenious (2009)', 'prediction': 4.742213249206543}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae541'), 'user': 29, 'movie': 126397, 'title': 'The Encounter (2010)', 'prediction': 4.7365336418151855}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae542'), 'user': 29, 'movie': 25749, 'title': 'Marriage Circle, The (1924)', 'prediction': 4.730412483215332}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae543'), 'user': 29, 'movie': 116141, 'title': 'The Russian Novel (2013)', 'prediction': 4.722355842590332}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae544'), 'user': 29, 'movie': 113315, 'title': 'Zero Motivation (Efes beyahasei enosh) (2014)', 'prediction': 4.716967582702637}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae545'), 'user': 29, 'movie': 79346, 'title': 'Smashing Pumpkins: If All Goes Wrong (2008)', 'prediction': 4.716765403747559}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae546'), 'user': 29, 'movie': 103593, 'title': 'Taming the Fire (Ukroshcheniye ognya) (1972)', 'prediction': 4.699819564819336}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae547'), 'user': 29, 'movie': 89819, 'title': 'Punk in London (1977)', 'prediction': 4.694857120513916}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae548'), 'user': 29, 'movie': 116951, 'title': 'Bo Burnham: what. (2013)', 'prediction': 4.6923298835754395}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae549'), 'user': 29, 'movie': 80417, 'title': 'Io Island (Iodo) (1977)', 'prediction': 4.6912126541137695}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae54a'), 'user': 29, 'movie': 84234, 'title': 'Simple Simon (I rymden finns inga känslor) (2010)', 'prediction': 4.684553146362305}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae54b'), 'user': 29, 'movie': 106158, 'title': 'La discrète (1990)', 'prediction': 4.683810710906982}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae54c'), 'user': 29, 'movie': 101717, 'title': \"Elusive Summer of '68, The (Varljivo leto '68) (1984)\", 'prediction': 4.67782735824585}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae54d'), 'user': 29, 'movie': 26978, 'title': 'Kiss or Kill (1997)', 'prediction': 4.644302845001221}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae54e'), 'user': 29, 'movie': 105778, 'title': 'One Small Hitch (2013)', 'prediction': 4.63694429397583}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae54f'), 'user': 29, 'movie': 107382, 'title': 'Whoopi Goldberg Presents Moms Mabley (2013)', 'prediction': 4.630652904510498}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae550'), 'user': 29, 'movie': 125922, 'title': 'Gregory Go Boom (2013)', 'prediction': 4.622010707855225}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae551'), 'user': 29, 'movie': 67135, 'title': 'Night Has a Thousand Eyes (1948)', 'prediction': 4.614125728607178}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae552'), 'user': 29, 'movie': 120313, 'title': 'Otakus in Love (2004)', 'prediction': 4.61221981048584}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae553'), 'user': 29, 'movie': 107643, 'title': 'Here Without Me (Inja bedoone man) (2011)', 'prediction': 4.612094402313232}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae554'), 'user': 29, 'movie': 107713, 'title': 'Meat the Truth (2008)', 'prediction': 4.604612827301025}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae555'), 'user': 29, 'movie': 99724, 'title': 'K-11 (2012)', 'prediction': 4.60114049911499}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae556'), 'user': 29, 'movie': 84502, 'title': 'World According to Sesame Street, The (2006)', 'prediction': 4.595306396484375}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae557'), 'user': 29, 'movie': 79866, 'title': 'Schmatta: Rags to Riches to Rags (2009)', 'prediction': 4.591147422790527}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae558'), 'user': 29, 'movie': 130954, 'title': 'Guter Junge (2008)', 'prediction': 4.585842609405518}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae559'), 'user': 29, 'movie': 131027, 'title': 'But Forever in My Mind (1999)', 'prediction': 4.585842609405518}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae55a'), 'user': 29, 'movie': 107730, 'title': 'By the People: The Election of Barack Obama (2009)', 'prediction': 4.584399223327637}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae55b'), 'user': 29, 'movie': 102912, 'title': 'Hiroshima (2005)', 'prediction': 4.581598281860352}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae55c'), 'user': 29, 'movie': 93291, 'title': 'Stone Left Unturned, A (Kovat miehet) (2000)', 'prediction': 4.58035945892334}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae55d'), 'user': 29, 'movie': 86061, 'title': 'Question of Silence, A (De stilte rond Christine M.) (1982)', 'prediction': 4.5794243812561035}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae55e'), 'user': 29, 'movie': 105825, 'title': 'Mustasukkaisuus (1953)', 'prediction': 4.575901031494141}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae55f'), 'user': 29, 'movie': 89985, 'title': 'Trap: What Happened to Our Dream of Freedom, The (2007)', 'prediction': 4.568497180938721}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae560'), 'user': 29, 'movie': 110097, 'title': 'From Dad to Son (2012)', 'prediction': 4.568264484405518}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae561'), 'user': 29, 'movie': 128987, 'title': 'Lascars (2009)', 'prediction': 4.568264484405518}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae562'), 'user': 29, 'movie': 26459, 'title': 'Scarlet Pimpernel, The (1982)', 'prediction': 4.565831184387207}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae563'), 'user': 29, 'movie': 54326, 'title': 'Sierra, La (2005)', 'prediction': 4.560082912445068}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae564'), 'user': 29, 'movie': 130644, 'title': 'The Garden of Sinners - Chapter 5: Paradox Paradigm (2008)', 'prediction': 4.559390544891357}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae565'), 'user': 29, 'movie': 33426, 'title': '9 Souls (Nain souruzu) (2003)', 'prediction': 4.550878524780273}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae566'), 'user': 29, 'movie': 26232, 'title': 'Rejs (1970)', 'prediction': 4.5507001876831055}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae567'), 'user': 29, 'movie': 81117, 'title': 'Moth, The (Cma) (1980)', 'prediction': 4.547665119171143}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae568'), 'user': 29, 'movie': 62054, 'title': 'Friend Among Strangers, Stranger Among Friends (Svoy sredi chuzhikh, chuzhoy sredi svoikh) (1974)', 'prediction': 4.543562889099121}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae569'), 'user': 29, 'movie': 79775, 'title': 'Story of My Life, The (Mensonges et trahisons et plus si affinités...) (2004)', 'prediction': 4.54217529296875}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae56a'), 'user': 29, 'movie': 116183, 'title': \"It's Love I'm After (1937)\", 'prediction': 4.541598320007324}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae56b'), 'user': 29, 'movie': 99493, 'title': 'Girl Walk: All Day (2011)', 'prediction': 4.54046630859375}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae56c'), 'user': 29, 'movie': 25994, 'title': 'Salt of the Earth (1954)', 'prediction': 4.540359973907471}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae56d'), 'user': 29, 'movie': 69493, 'title': 'Tu£sday (2008)', 'prediction': 4.539155960083008}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae56e'), 'user': 29, 'movie': 84276, 'title': 'Stewart Lee: If You Prefer a Milder Comedian, Please Ask for One (2010)', 'prediction': 4.532973289489746}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae56f'), 'user': 29, 'movie': 88466, 'title': 'Broken Sky (El cielo dividido) (2006)', 'prediction': 4.532732009887695}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae570'), 'user': 29, 'movie': 69464, 'title': 'Angels of the Universe (Englar alheimsins) (2000)', 'prediction': 4.532115936279297}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae571'), 'user': 29, 'movie': 115699, 'title': 'Turning Tide (En solitaire) (2013)', 'prediction': 4.52728271484375}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae572'), 'user': 29, 'movie': 113244, 'title': 'When I Walk (2013)', 'prediction': 4.522505760192871}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae573'), 'user': 29, 'movie': 122290, 'title': 'Homeboy (1988)', 'prediction': 4.521353244781494}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae574'), 'user': 29, 'movie': 47460, 'title': 'Peking Opera Blues (Do ma daan) (1986)', 'prediction': 4.5202484130859375}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae575'), 'user': 29, 'movie': 68544, 'title': 'Stolen Collection, (Skradziona kolekcja) (1979)', 'prediction': 4.512984752655029}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae576'), 'user': 29, 'movie': 130034, 'title': 'Stand by Me Doraemon (2014)', 'prediction': 4.507497310638428}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae577'), 'user': 29, 'movie': 92496, 'title': 'Dylan Moran: Like, Totally (2006)', 'prediction': 4.507258415222168}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae578'), 'user': 29, 'movie': 80195, 'title': 'Shouting Fire: Stories from the Edge of Free Speech (2009)', 'prediction': 4.500058650970459}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae579'), 'user': 29, 'movie': 109925, 'title': 'It Is Written in the Stars, Inspector Palmu (Tähdet kertovat, komisario Palmu) (1962)', 'prediction': 4.497852325439453}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae57a'), 'user': 29, 'movie': 103863, 'title': 'Holidays by the Sea (Ni à vendre ni à louer) (2011)', 'prediction': 4.490893363952637}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae57b'), 'user': 29, 'movie': 56548, 'title': 'All Passion Spent (1986)', 'prediction': 4.488989353179932}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae57c'), 'user': 29, 'movie': 102495, 'title': 'Spine Tingler!  The William Castle Story (2007)', 'prediction': 4.484663009643555}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae57d'), 'user': 29, 'movie': 26674, 'title': 'Prime Suspect (1991)', 'prediction': 4.479827880859375}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae57e'), 'user': 29, 'movie': 100060, 'title': 'Sunny (Sseo-ni) (2011)', 'prediction': 4.477886199951172}\n",
      "{'_id': ObjectId('6818ba8c4c93bd75c4aae57f'), 'user': 29, 'movie': 112990, 'title': 'Pursuit of Unhappiness, The (Anleitung zum Unglücklichsein) (2012)', 'prediction': 4.473030090332031}\n"
     ]
    }
   ],
   "source": [
    "for doc in collection.find({\"user\": 29}):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6e4b89-a2a1-4e36-a489-208dde607dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.mongodb.spark#mongo-spark-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-1850713e-7cbf-439b-b86f-13badd79f9d5;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mongodb.spark#mongo-spark-connector_2.12;10.1.1 in central\n",
      "\tfound org.mongodb#mongodb-driver-sync;4.8.2 in central\n",
      "\t[4.8.2] org.mongodb#mongodb-driver-sync;[4.8.1,4.8.99)\n",
      "\tfound org.mongodb#bson;4.8.2 in central\n",
      "\tfound org.mongodb#mongodb-driver-core;4.8.2 in central\n",
      "\tfound org.mongodb#bson-record-codec;4.8.2 in central\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/10.1.1/mongo-spark-connector_2.12-10.1.1.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb.spark#mongo-spark-connector_2.12;10.1.1!mongo-spark-connector_2.12.jar (39ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-sync/4.8.2/mongodb-driver-sync-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-sync;4.8.2!mongodb-driver-sync.jar (24ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson/4.8.2/bson-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson;4.8.2!bson.jar (47ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/mongodb-driver-core/4.8.2/mongodb-driver-core-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#mongodb-driver-core;4.8.2!mongodb-driver-core.jar (101ms)\n",
      "downloading https://repo1.maven.org/maven2/org/mongodb/bson-record-codec/4.8.2/bson-record-codec-4.8.2.jar ...\n",
      "\t[SUCCESSFUL ] org.mongodb#bson-record-codec;4.8.2!bson-record-codec.jar (25ms)\n",
      ":: resolution report :: resolve 1601ms :: artifacts dl 243ms\n",
      "\t:: modules in use:\n",
      "\torg.mongodb#bson;4.8.2 from central in [default]\n",
      "\torg.mongodb#bson-record-codec;4.8.2 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-core;4.8.2 from central in [default]\n",
      "\torg.mongodb#mongodb-driver-sync;4.8.2 from central in [default]\n",
      "\torg.mongodb.spark#mongo-spark-connector_2.12;10.1.1 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   5   |   5   |   0   ||   5   |   5   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-1850713e-7cbf-439b-b86f-13badd79f9d5\n",
      "\tconfs: [default]\n",
      "\t5 artifacts copied, 0 already retrieved (2354kB/9ms)\n",
      "25/05/05 13:04:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WriteToMongoDB\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:10.1.1\") \\\n",
    "    .config(\"spark.mongodb.write.connection.uri\", \"mongodb://mongodb:27017/reco_db.predictions\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314eca15-d268-4cb0-9b8c-c5fcdb78f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/05 13:04:43 ERROR Executor: Exception in task 7.0 in stage 0.0 (TID 7) 12]\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 5.0 in stage 0.0 (TID 5)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 3.0 in stage 0.0 (TID 3)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 8.0 in stage 0.0 (TID 8)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 10.0 in stage 0.0 (TID 10)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 6.0 in stage 0.0 (TID 6)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 11.0 in stage 0.0 (TID 11)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 1.0 in stage 0.0 (TID 1)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 9.0 in stage 0.0 (TID 9)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 4.0 in stage 0.0 (TID 4)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 ERROR Executor: Exception in task 2.0 in stage 0.0 (TID 2)\n",
      "java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/05 13:04:43 WARN TaskSetManager: Lost task 11.0 in stage 0.0 (TID 11) (namenode executor driver): java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n",
      "\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n",
      "\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n",
      "\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n",
      "\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n",
      "25/05/05 13:04:43 ERROR TaskSetManager: Task 11 in stage 0.0 failed 1 times; aborting job\n",
      "25/05/05 13:04:43 ERROR OverwriteByExpressionExec: Data source write support com.mongodb.spark.sql.connector.write.MongoBatchWrite@13b8e0ff is aborting.\n",
      "25/05/05 13:04:43 ERROR OverwriteByExpressionExec: Data source write support com.mongodb.spark.sql.connector.write.MongoBatchWrite@13b8e0ff failed to abort.\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o55.save.\n: org.apache.spark.SparkException: Writing job failed.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.writingJobFailedError(QueryExecutionErrors.scala:902)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:411)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:243)\n\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run(WriteToDataSourceV2Exec.scala:337)\n\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run$(WriteToDataSourceV2Exec.scala:336)\n\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:243)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:319)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 0.0 failed 1 times, most recent failure: Lost task 11.0 in stage 0.0 (TID 11) (namenode executor driver): java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n\t... 44 more\n\tSuppressed: com.mongodb.spark.sql.connector.exceptions.DataException: Write aborted for: c8ec8a57-2024-4c90-9e8b-dc6430b53448. 0/12 tasks completed.\n\t\tat com.mongodb.spark.sql.connector.write.MongoBatchWrite.abort(MongoBatchWrite.java:95)\n\t\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:406)\n\t\t... 44 more\nCaused by: java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39mcreateDataFrame(data, columns)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Écriture dans MongoDB (base: reco_db, collection: predictions)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmongodb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatabase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreco_db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredictions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muri\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmongodb://mongodb:27017/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m---> 15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py:1461\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o55.save.\n: org.apache.spark.SparkException: Writing job failed.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.writingJobFailedError(QueryExecutionErrors.scala:902)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:411)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:359)\n\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:243)\n\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run(WriteToDataSourceV2Exec.scala:337)\n\tat org.apache.spark.sql.execution.datasources.v2.V2ExistingTableWriteExec.run$(WriteToDataSourceV2Exec.scala:336)\n\tat org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:243)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43)\n\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:125)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:201)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:108)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:900)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:66)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:107)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:461)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:32)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:437)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:98)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:85)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:142)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:859)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:319)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 0.0 failed 1 times, most recent failure: Lost task 11.0 in stage 0.0 (TID 11) (namenode executor driver): java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2856)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2792)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2791)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2791)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1247)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1247)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3060)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2994)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2983)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:989)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2398)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:385)\n\t... 44 more\n\tSuppressed: com.mongodb.spark.sql.connector.exceptions.DataException: Write aborted for: c8ec8a57-2024-4c90-9e8b-dc6430b53448. 0/12 tasks completed.\n\t\tat com.mongodb.spark.sql.connector.write.MongoBatchWrite.abort(MongoBatchWrite.java:95)\n\t\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:406)\n\t\t... 44 more\nCaused by: java.lang.NoSuchMethodError: 'org.apache.spark.sql.catalyst.encoders.ExpressionEncoder org.apache.spark.sql.catalyst.encoders.RowEncoder$.apply(org.apache.spark.sql.types.StructType)'\n\tat com.mongodb.spark.sql.connector.schema.InternalRowToRowFunction.<init>(InternalRowToRowFunction.java:46)\n\tat com.mongodb.spark.sql.connector.schema.RowToBsonDocumentConverter.<init>(RowToBsonDocumentConverter.java:80)\n\tat com.mongodb.spark.sql.connector.write.MongoDataWriter.<init>(MongoDataWriter.java:78)\n\tat com.mongodb.spark.sql.connector.write.MongoDataWriterFactory.createWriter(MongoDataWriterFactory.java:54)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run(WriteToDataSourceV2Exec.scala:436)\n\tat org.apache.spark.sql.execution.datasources.v2.WritingSparkTask.run$(WriteToDataSourceV2Exec.scala:425)\n\tat org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask$.run(WriteToDataSourceV2Exec.scala:491)\n\tat org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.$anonfun$writeWithV2$2(WriteToDataSourceV2Exec.scala:388)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:93)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:166)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:141)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:620)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally(SparkErrorUtils.scala:64)\n\tat org.apache.spark.util.SparkErrorUtils.tryWithSafeFinally$(SparkErrorUtils.scala:61)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:94)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:623)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Exemple de DataFrame à insérer (remplace par result_cleaned_df)\n",
    "data = [(29, 1, \"Film 1\", 4.5), (29, 2, \"Film 2\", 4.0)]\n",
    "columns = [\"user\", \"movie\", \"title\", \"prediction\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Écriture dans MongoDB (base: reco_db, collection: predictions)\n",
    "df.write \\\n",
    "    .format(\"mongodb\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"database\", \"reco_db\") \\\n",
    "    .option(\"collection\", \"predictions\") \\\n",
    "    .option(\"uri\", \"mongodb://mongodb:27017/\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6dafe49d-27a9-4b31-b012-d5e618237e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------------------------------------------------------------------------------------------------------+----------+\n",
      "|user|movie |title                                                                                                 |prediction|\n",
      "+----+------+------------------------------------------------------------------------------------------------------+----------+\n",
      "|29  |128091|Craig Ferguson: A Wee Bit o' Revolution (2009)                                                        |6.5495496 |\n",
      "|29  |121029|No Distance Left to Run (2010)                                                                        |5.922186  |\n",
      "|29  |77736 |Crazy Stone (Fengkuang de shitou) (2006)                                                              |5.7918434 |\n",
      "|29  |129536|Code Name Coq Rouge (1989)                                                                            |5.3435593 |\n",
      "|29  |99243 |Parasites, Les (1999)                                                                                 |5.1454844 |\n",
      "|29  |102119|Yesterday Was a Lie (2008)                                                                            |5.1318784 |\n",
      "|29  |98275 |Octopus, The (Le poulpe) (1998)                                                                       |5.098303  |\n",
      "|29  |120134|Doggiewoggiez! Poochiewoochiez! (2012)                                                                |4.9880137 |\n",
      "|29  |107623|2013 Rock and Roll Hall of Fame Induction Ceremony, The (2013)                                        |4.980217  |\n",
      "|29  |104103|Miss You Can Do It (2013)                                                                             |4.980217  |\n",
      "|29  |79348 |Pearl Jam: Immagine in Cornice - Live in Italy 2006 (2007)                                            |4.9776764 |\n",
      "|29  |100196|Tom Petty and the Heartbreakers: Runnin' Down a Dream (2007)                                          |4.9523377 |\n",
      "|29  |130347|Bill Hicks: Sane Man (1989)                                                                           |4.939438  |\n",
      "|29  |96631 |Deathstalker II (1987)                                                                                |4.928587  |\n",
      "|29  |98328 |Chronicle of My Mother (Waga haha no ki) (2011)                                                       |4.923467  |\n",
      "|29  |109887|Great Passage, The (Fune wo amu) (2013)                                                               |4.923467  |\n",
      "|29  |113555|It Runs in the Family (My Summer Story) (1994)                                                        |4.9078717 |\n",
      "|29  |102107|American Winter (2013)                                                                                |4.8937654 |\n",
      "|29  |72235 |Between the Devil and the Deep Blue Sea (1995)                                                        |4.8588862 |\n",
      "|29  |113043|Loser Takes All! (Qui perd gagne !) (2003)                                                            |4.856163  |\n",
      "|29  |95776 |Bob Funk (2009)                                                                                       |4.8555307 |\n",
      "|29  |89056 |Company: Original Cast Album (1970)                                                                   |4.82715   |\n",
      "|29  |7568  |Love Life (2001)                                                                                      |4.8259597 |\n",
      "|29  |101319|Operation Daybreak (1975)                                                                             |4.8234453 |\n",
      "|29  |107306|Gurren Lagann: The Lights in the Sky are Stars (Gekijô ban Tengen toppa guren ragan: Ragan hen) (2009)|4.8223424 |\n",
      "|29  |126723|Kenny Begins (2009)                                                                                   |4.7995872 |\n",
      "|29  |129514|George Carlin: It's Bad for Ya! (2008)                                                                |4.795023  |\n",
      "|29  |107743|Class of 92, The (2013)                                                                               |4.793573  |\n",
      "|29  |128187|Freedom Song (2000)                                                                                   |4.780411  |\n",
      "|29  |56869 |Drained (O cheiro do Ralo) (2006)                                                                     |4.77037   |\n",
      "+----+------+------------------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o870.save.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: mongodb. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n\tat org.apache.spark.sql.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:863)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:257)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: mongodb.DefaultSource\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n\tat scala.util.Failure.orElse(Try.scala:224)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n\t... 16 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m result_df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmovie\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      3\u001b[0m          \u001b[38;5;241m.\u001b[39morderBy(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdesc()) \\\n\u001b[1;32m      4\u001b[0m          \u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m30\u001b[39m, truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Écriture dans MongoDB\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[43mresult_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmongodb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatabase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreco_db\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcollection\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredictions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muri\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmongodb://localhost:27017/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m---> 13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py:1461\u001b[0m, in \u001b[0;36mDataFrameWriter.save\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jwrite\u001b[38;5;241m.\u001b[39msave(path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o870.save.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: mongodb. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n\tat org.apache.spark.sql.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:863)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:257)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: mongodb.DefaultSource\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n\tat scala.util.Failure.orElse(Try.scala:224)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n\t... 16 more\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage : enlever les valeurs NaN (optionnel mais recommandé)\n",
    "result_df.select(\"user\", \"movie\", \"title\", \"prediction\") \\\n",
    "         .orderBy(col(\"prediction\").desc()) \\\n",
    "         .show(30, truncate=False)\n",
    "\n",
    "# Écriture dans MongoDB\n",
    "result_df.write \\\n",
    "    .format(\"mongodb\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"database\", \"reco_db\") \\\n",
    "    .option(\"collection\", \"predictions\") \\\n",
    "    .option(\"uri\", \"mongodb://localhost:27017/\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3371f-86b4-4392-9a2d-e6a70520d06a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
