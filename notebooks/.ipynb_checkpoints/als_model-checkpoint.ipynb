{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7545919a-50ef-4db4-a3b7-5f30d5ddc194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Downloading numpy-2.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-2.2.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead476f0-f4ec-487c-85fa-e9f22932c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ba17c6-1a03-4dd4-b48e-4d13f4b9d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/30 17:28:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#spark = SparkSession.builder \\\n",
    "    #.appName(\"Read MovieLens from HDFS\") \\\n",
    "    #.getOrCreate()\n",
    "\n",
    "#spark = SparkSession.builder \\\n",
    "    #.appName(\"ALS Model\") \\\n",
    "    #.config(\"spark.driver.memory\", \"4g\") \\\n",
    "    #.config(\"spark.executor.memory\", \"4g\") \\\n",
    "   # .getOrCreate()\n",
    "\n",
    "#.config(\"spark.hadoop.fs.defaultFS\", \"hdfs://bigdata-node:8088\") \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieLensAnalysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"20\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbdc33e-314d-4254-992c-35d777a1b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.option(\"header\", True).csv(\"hdfs:///data/rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f9682b9-402b-482a-a56d-24d142d47d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "067bac6e-0730-4491-9998-aba578134958",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.read.option(\"header\", True).csv(\"hdfs:///data/movie.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6229fbbe-6d7b-4578-b13c-821664be40c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06278d09-4288-42f7-80d1-da3ef32d9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = ratings_df.join(\n",
    "    movies_df.select(\"movieId\", \"title\"),\n",
    "    on=\"movieId\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63753215-bcbc-41f4-a201-845eabf65bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+--------------------+\n",
      "|movieId|userId|rating|          timestamp|               title|\n",
      "+-------+------+------+-------------------+--------------------+\n",
      "|      2|     1|   3.5|2005-04-02 23:53:47|      Jumanji (1995)|\n",
      "|     29|     1|   3.5|2005-04-02 23:31:16|City of Lost Chil...|\n",
      "|     32|     1|   3.5|2005-04-02 23:33:39|Twelve Monkeys (a...|\n",
      "|     47|     1|   3.5|2005-04-02 23:32:07|Seven (a.k.a. Se7...|\n",
      "|     50|     1|   3.5|2005-04-02 23:29:40|Usual Suspects, T...|\n",
      "+-------+------+------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "002f42d9-7288-46a9-a49a-67a28b5d3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.withColumnsRenamed({\n",
    "    'userId': 'user',\n",
    "    'movieId': 'movie',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa80e461-4542-48d9-b803-beec718aabb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+-------------------+--------------------+\n",
      "|movie|user|rating|          timestamp|               title|\n",
      "+-----+----+------+-------------------+--------------------+\n",
      "|    2|   1|   3.5|2005-04-02 23:53:47|      Jumanji (1995)|\n",
      "|   29|   1|   3.5|2005-04-02 23:31:16|City of Lost Chil...|\n",
      "|   32|   1|   3.5|2005-04-02 23:33:39|Twelve Monkeys (a...|\n",
      "|   47|   1|   3.5|2005-04-02 23:32:07|Seven (a.k.a. Se7...|\n",
      "|   50|   1|   3.5|2005-04-02 23:29:40|Usual Suspects, T...|\n",
      "+-----+----+------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d5f476-a971-48b2-9abc-614c68392e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_data = df_data \\\n",
    "    .withColumn(\"user\", col(\"user\").cast(\"int\")) \\\n",
    "    .withColumn(\"movie\", col(\"movie\").cast(\"int\")) \\\n",
    "    .withColumn(\"rating\", col(\"rating\").cast(\"float\")) \\\n",
    "    .withColumn(\"timestamp\", col(\"timestamp\").cast(\"int\")) \\\n",
    "    .withColumn(\"title\", col(\"title\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a7466fe-735f-4b66-89ec-5aeba43e6287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train, df_data_test = df_data.randomSplit([0.8, 0.2], 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167be899-c3e6-48dc-bad4-add72e4eda5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# import ALS model from spark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# initialise the model \n",
    "als = ALS(maxIter=10, regParam=0.1, rank=10, userCol=\"user\", itemCol=\"movie\", \n",
    "          ratingCol=\"rating\", coldStartStrategy=\"drop\", nonnegative=True)\n",
    "\n",
    "# train model \n",
    "als_model = als.fit(df_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4aed8342-8627-499e-b635-bdf46a464118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 195:=================================>                     (12 + 8) / 20]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.8134684540727374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = als_model.transform(df_data_test)  # ou train, selon ce que tu veux\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"RMSE = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0156a30c-dfb1-48c0-80af-44d70930c46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
