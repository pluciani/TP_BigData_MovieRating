{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7545919a-50ef-4db4-a3b7-5f30d5ddc194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead476f0-f4ec-487c-85fa-e9f22932c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ba17c6-1a03-4dd4-b48e-4d13f4b9d3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/02 14:21:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#spark = SparkSession.builder \\\n",
    "    #.appName(\"Read MovieLens from HDFS\") \\\n",
    "    #.getOrCreate()\n",
    "\n",
    "#spark = SparkSession.builder \\\n",
    "    #.appName(\"ALS Model\") \\\n",
    "    #.config(\"spark.driver.memory\", \"4g\") \\\n",
    "    #.config(\"spark.executor.memory\", \"4g\") \\\n",
    "   # .getOrCreate()\n",
    "\n",
    "#.config(\"spark.hadoop.fs.defaultFS\", \"hdfs://bigdata-node:8088\") \\\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MovieLensAnalysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "    .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"20\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda08717",
   "metadata": {},
   "source": [
    "Lire les fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dbdc33e-314d-4254-992c-35d777a1b516",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.option(\"header\", True).csv(\"hdfs:///data/rating.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "5f9682b9-402b-482a-a56d-24d142d47d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+-------------------+\n",
      "|userId|movieId|rating|          timestamp|\n",
      "+------+-------+------+-------------------+\n",
      "|     1|      2|   3.5|2005-04-02 23:53:47|\n",
      "|     1|     29|   3.5|2005-04-02 23:31:16|\n",
      "|     1|     32|   3.5|2005-04-02 23:33:39|\n",
      "|     1|     47|   3.5|2005-04-02 23:32:07|\n",
      "|     1|     50|   3.5|2005-04-02 23:29:40|\n",
      "+------+-------+------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6229fbbe-6d7b-4578-b13c-821664be40c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|movieId|               title|              genres|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|      Jumanji (1995)|Adventure|Childre...|\n",
      "|      3|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      4|Waiting to Exhale...|Comedy|Drama|Romance|\n",
      "|      5|Father of the Bri...|              Comedy|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06278d09-4288-42f7-80d1-da3ef32d9fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = ratings_df.join(\n",
    "    movies_df.select(\"movieId\", \"title\"),\n",
    "    on=\"movieId\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63753215-bcbc-41f4-a201-845eabf65bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+-------------------+--------------------+\n",
      "|movieId|userId|rating|          timestamp|               title|\n",
      "+-------+------+------+-------------------+--------------------+\n",
      "|      2|     1|   3.5|2005-04-02 23:53:47|      Jumanji (1995)|\n",
      "|     29|     1|   3.5|2005-04-02 23:31:16|City of Lost Chil...|\n",
      "|     32|     1|   3.5|2005-04-02 23:33:39|Twelve Monkeys (a...|\n",
      "|     47|     1|   3.5|2005-04-02 23:32:07|Seven (a.k.a. Se7...|\n",
      "|     50|     1|   3.5|2005-04-02 23:29:40|Usual Suspects, T...|\n",
      "+-------+------+------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "002f42d9-7288-46a9-a49a-67a28b5d3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = df_data.withColumnsRenamed({\n",
    "    'userId': 'user',\n",
    "    'movieId': 'movie',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa80e461-4542-48d9-b803-beec718aabb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+-------------------+--------------------+\n",
      "|movie|user|rating|          timestamp|               title|\n",
      "+-----+----+------+-------------------+--------------------+\n",
      "|    2|   1|   3.5|2005-04-02 23:53:47|      Jumanji (1995)|\n",
      "|   29|   1|   3.5|2005-04-02 23:31:16|City of Lost Chil...|\n",
      "|   32|   1|   3.5|2005-04-02 23:33:39|Twelve Monkeys (a...|\n",
      "|   47|   1|   3.5|2005-04-02 23:32:07|Seven (a.k.a. Se7...|\n",
      "|   50|   1|   3.5|2005-04-02 23:29:40|Usual Suspects, T...|\n",
      "+-----+----+------+-------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d5f476-a971-48b2-9abc-614c68392e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_data = df_data \\\n",
    "    .withColumn(\"user\", col(\"user\").cast(\"int\")) \\\n",
    "    .withColumn(\"movie\", col(\"movie\").cast(\"int\")) \\\n",
    "    .withColumn(\"rating\", col(\"rating\").cast(\"float\")) \\\n",
    "    .withColumn(\"timestamp\", col(\"timestamp\").cast(\"int\")) \\\n",
    "    .withColumn(\"title\", col(\"title\").cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a7466fe-735f-4b66-89ec-5aeba43e6287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train, df_data_test = df_data.randomSplit([0.8, 0.2], 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "167be899-c3e6-48dc-bad4-add72e4eda5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/02 14:22:16 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# import ALS model from spark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# initialise the model \n",
    "als = ALS(maxIter=10, regParam=0.1, rank=10, userCol=\"user\", itemCol=\"movie\", \n",
    "          ratingCol=\"rating\", coldStartStrategy=\"drop\", nonnegative=True)\n",
    "\n",
    "# train model \n",
    "als_model = als.fit(df_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "376f6658-da74-496e-ba0c-4daf4c7c5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_preds = als_model.transform(df_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d35d13e-9426-44fb-b4a8-bfc5edbc1205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 114:==================================================>    (11 + 1) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+---------+--------------------+----------+\n",
      "|movie|user|rating|timestamp|               title|prediction|\n",
      "+-----+----+------+---------+--------------------+----------+\n",
      "|   47|  95|   3.0|     NULL|Seven (a.k.a. Se7...|  3.078373|\n",
      "|  262|  95|   3.0|     NULL|Little Princess, ...|  3.438147|\n",
      "|  446|  95|   3.0|     NULL|Farewell My Concu...| 3.5873995|\n",
      "|  592|  95|   3.0|     NULL|       Batman (1989)|  2.504309|\n",
      "|  708|  95|   4.0|     NULL|Truth About Cats ...|  3.118482|\n",
      "+-----+----+------+---------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "dfs_preds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c131d101-ca69-42f3-93f3-0c0f8d3f54c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o195.save.\n: java.io.IOException: Path hdfs:///data/als_prediction_rating already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mals_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhdfs:///data/als_prediction_rating\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/util.py:262\u001b[0m, in \u001b[0;36mMLWritable.save\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Save this ML instance to the given path, a shortcut of 'write().save(path)'.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/ml/util.py:213\u001b[0m, in \u001b[0;36mJavaMLWriter.save\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath should be a string, got type \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(path))\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py:179\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o195.save.\n: java.io.IOException: Path hdfs:///data/als_prediction_rating already exists. To overwrite it, please use write.overwrite().save(path) for Scala and use write().overwrite().save(path) for Java and Python.\n\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:683)\n\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "als_model.save(\"hdfs:///data/als_prediction_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8454468-2ce4-4ecb-bf96-9fd20df144a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "\n",
    "als_model_loaded = ALSModel.load(\"hdfs:///data/als_prediction_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5004f194-c3c8-41aa-9ee5-dd7fd1b0fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_preds_loaded = als_model_loaded.transform(df_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80881729-ae39-4c05-8360-ff6a0a0510bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+---------+----------------+----------+\n",
      "|movie|user|rating|timestamp|           title|prediction|\n",
      "+-----+----+------+---------+----------------+----------+\n",
      "|    1|   8|   4.0|     NULL|Toy Story (1995)| 4.1200004|\n",
      "|    1|  13|   4.0|     NULL|Toy Story (1995)|    3.5436|\n",
      "|    1|  16|   3.0|     NULL|Toy Story (1995)| 3.7518215|\n",
      "|    1|  31|   3.0|     NULL|Toy Story (1995)| 3.0558991|\n",
      "|    1|  58|   5.0|     NULL|Toy Story (1995)|   4.34349|\n",
      "+-----+----+------+---------+----------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "dfs_preds_loaded.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c10a083-5f7b-44a8-a2c9-7f6621ebb40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 149:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+---------+----------------+\n",
      "|movie|user|rating|timestamp|           title|\n",
      "+-----+----+------+---------+----------------+\n",
      "|    1|   8|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1|  13|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1|  16|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1|  31|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1|  58|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1|  80|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1|  96|   3.5|     NULL|Toy Story (1995)|\n",
      "|    1| 114|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1| 134|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1| 135|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1| 136|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 140|   4.0|     NULL|Toy Story (1995)|\n",
      "|    1| 144|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1| 155|   2.5|     NULL|Toy Story (1995)|\n",
      "|    1| 172|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 204|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 232|   3.0|     NULL|Toy Story (1995)|\n",
      "|    1| 296|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 318|   5.0|     NULL|Toy Story (1995)|\n",
      "|    1| 330|   4.0|     NULL|Toy Story (1995)|\n",
      "+-----+----+------+---------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_data_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be25fa01-15f4-47fe-a548-18fc446afc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 168:================================>                       (7 + 5) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score = 0.8157736828362929\n",
      "R2 score = 0.39869052585871656\n",
      "MAE score = 0.6375367684273177\n",
      "Explained variance score = 0.4086564056899666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# initiate evaluator\n",
    "eval = RegressionEvaluator(metricName='rmse', labelCol='rating', predictionCol='prediction')\n",
    "# calculate rmse\n",
    "rmse = eval.evaluate(dfs_preds_loaded)\n",
    "\n",
    "# reset metric and evaluate mse, R2, mae & explained variance\n",
    "r2 = eval.evaluate(dfs_preds_loaded, {eval.metricName: 'r2'})\n",
    "mae = eval.evaluate(dfs_preds_loaded, {eval.metricName: 'mae'})\n",
    "var = eval.evaluate(dfs_preds_loaded, {eval.metricName: 'var'})\n",
    "\n",
    "\n",
    "print(\n",
    "    \"RMSE score = {}\".format(rmse),\n",
    "    \"R2 score = {}\".format(r2),\n",
    "    \"MAE score = {}\".format(mae),\n",
    "    \"Explained variance score = {}\".format(var),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
